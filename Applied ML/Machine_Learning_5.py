#%% ensure pandas is installed and workingimport pandas as pdimport numpy as npimport sklearn.preprocessing as prepfrom sklearn.model_selection import train_test_splitfrom our_DA_selector import da_model_selector, decision_surface_2dtest = pd.DataFrame({'x': [0,1,2,3,4,5], 'y':[8,7,6,4,5,3]})test.head()#%% make sure working directory is set correctly and all data are in subfolder "data"df_orig_WS = pd.read_csv('data/Wholesale.csv')df = df_orig_WS.copy() df.head()df.describe()#%% data preprocessing: adjust data type for categorical features# change in order to get meaningful numbers and labels Hotel Restaurant Cafeteriadf['Channel'] = df_orig_WS['Channel'].astype('category')labels_chan = {1: 'HoReCa', 2: 'Retail'}df['Channel'] = df['Channel'].cat.rename_categories(labels_chan)#%%print(df['Channel'].describe())print(df['Channel'].cat.categories)#%%df['Region'] = pd.cut(df['Region'], bins = [0,1,2,3], labels=['Lisbon', 'Oporto', 'other'], right=True)labels_reg = dict(  zip(np.arange(1,4), ['Lisbon', 'Oporto', 'other'])  )df['Region'] = df_orig_WS['Region'].astype('category').cat.rename_categories(labels_reg)print(df.Region.describe())print(df['Region'].value_counts())#%% add and remove a featuredf['combi'] = df.Region.astype('str') + '_' + df.Channel.astype('str')print(df)df.drop('combi', axis=1,inplace=True)print(df)# Save a file as csvdf.to_csv("data/_wholesale_cat.csv", index=False)#%% check if seaborn is workingimport seaborn as sns# Plot the data in order to look at the distribution# Unfortunately this data is not distributed nicely at all# E.g. Frozen will definetely not work if using LDA! Different covariances# In particular blue groups are skewed and non-normal# positive outliers lead to positive skewness, mean is bigger than the median.# Excess kurtosis, if we have more outliers than normal distribution (leptokurtic)# Outliers will either have no effect or large effect (if it is far away to the right on the scatter, it has a huge impact)sns.pairplot(df, hue='Channel')#%% Preprocessingdf_orig_WS["Channel"] = df_orig_WS["Channel"].astype("category")df_orig_WS["Region"]  = df_orig_WS["Region"].astype("category")y = df_orig_WS["Region"]X = df_orig_WS.drop(["Channel", "Region"], axis=1)nIter  = 50res_is = []res_os = []for it in range(nIter):    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)        # Scaling Data        # Fit the scaler with training data and then apply to test, validation and real world    scaler = prep.StandardScaler()    scaler = prep. MinMaxScaler()        scaler.fit(X_train)    X_train[:] = scaler.transform(X_train)    X_test[:] = scaler.transform(X_test)        # Log is not always good idea to get better distribution, sometimes need box-cox            method = ("knn", {"n_neighbors":10})        model = da_model_selector(method)        model.fit(X_train, y_train)        accIS = model.score(X_train, y_train)    accOS = model.score(X_test, y_test)        res_is.append(accIS)    res_os.append(accOS)print(np.mean(res_is))print(np.mean(res_os))#%% check sklearn is working: linear regressionimport sklearn.linear_model as lmmodel = lm.LinearRegression()Chan_Dummies = pd.get_dummies(df['Channel'], prefix='Channel', drop_first=True)dfC = pd.concat( (df, Chan_Dummies), axis=1 )X=dfC[['Detergents_Paper', 'Channel_Retail']]y=dfC['Grocery']model.fit(X,y)print(f'intercept: {model.intercept_} \t parameters:  {model.coef_}')print(f'R^2 = {model.score(X,y)}')#%% OLS with statsmodelsimport statsmodels.api as smols = sm.OLS(y,sm.add_constant(X.astype('float')))res = ols.fit()print(res.summary())